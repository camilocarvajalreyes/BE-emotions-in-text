{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis of written text\n",
    "Author: Camilo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set\n",
    "We load the EmoBank data set\n",
    "\n",
    "https://github.com/JULIELab/EmoBank\n",
    "\n",
    "Sven Buechel and Udo Hahn. 2017. EmoBank: Studying the Impact of Annotation Perspective and Representation Format on Dimensional Emotion Analysis. In EACL 2017 - Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics. Valencia, Spain, April 3-7, 2017. Volume 2, Short Papers, pages 578-585. Available: http://aclweb.org/anthology/E17-2092\n",
    "\n",
    "Sven Buechel and Udo Hahn. 2017. Readers vs. writers vs. texts: Coping with different perspectives of text understanding in emotion annotation. In LAW 2017 - Proceedings of the 11th Linguistic Annotation Workshop @ EACL 2017. Valencia, Spain, April 3, 2017, pages 1-12. Available: https://sigann.github.io/LAW-XI-2017/papers/LAW01.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>V</th>\n",
       "      <th>A</th>\n",
       "      <th>D</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.20</td>\n",
       "      <td>Remember what she said in my last letter? \"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.80</td>\n",
       "      <td>If I wasn't working here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>..\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.22</td>\n",
       "      <td>Goodwill helps people get off of public assistance.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>3.55</td>\n",
       "      <td>3.27</td>\n",
       "      <td>3.46</td>\n",
       "      <td>Sherry learned through our Future Works class that she could rise out of the mire of the welfare system and support ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   split     V     A     D  \\\n",
       "0  train  3.00  3.00  3.20   \n",
       "1   test  2.80  3.10  2.80   \n",
       "2  train  3.00  3.00  3.00   \n",
       "3  train  3.44  3.00  3.22   \n",
       "4  train  3.55  3.27  3.46   \n",
       "\n",
       "                                                                                                                      text  \n",
       "0                                                                              Remember what she said in my last letter? \"  \n",
       "1                                                                                                If I wasn't working here.  \n",
       "2                                                                                                                      ..\"  \n",
       "3                                                                      Goodwill helps people get off of public assistance.  \n",
       "4  Sherry learned through our Future Works class that she could rise out of the mire of the welfare system and support ...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eb = pd.read_csv(\"C:\\\\Users\\\\fast\\\\camilo\\\\ST7\\\\EmoBank-master\\\\corpus\\\\emobank.csv\")\n",
    "pd.set_option('max_colwidth', 120)\n",
    "eb = eb.drop(['id'], axis=1)\n",
    "eb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histograms of Valence, Arousal and Dominance respectively\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x216 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##### import matplotlib.pyplot as plt\n",
    "\n",
    "print('Histograms of Valence, Arousal and Dominance respectively')\n",
    "valence, arousal, dominance = eb['V'], eb['A'], eb['D']\n",
    "VAR = [valence, arousal, dominance]\n",
    "fig, axes = plt.subplots(1,3,figsize=(16,3))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.hist(VAR[i], bins=50) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NRC VAD lexicon\n",
    "\n",
    "Using lexicons from Saif M. Mohammad: http://www.saifmohammad.com/WebPages/lexicons.html\n",
    "\n",
    "And pre-trained word embedding vectors: https://nlp.stanford.edu/projects/glove/\n",
    "\n",
    "Obtaining Reliable Human Ratings of Valence, Arousal, and Dominance for 20,000 English Words. Saif M. Mohammad. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, Melbourne, Australia, July 2018.\n",
    "\n",
    "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valence</th>\n",
       "      <th>arousal</th>\n",
       "      <th>dominance</th>\n",
       "      <th>dim_1</th>\n",
       "      <th>dim_2</th>\n",
       "      <th>dim_3</th>\n",
       "      <th>dim_4</th>\n",
       "      <th>dim_5</th>\n",
       "      <th>dim_6</th>\n",
       "      <th>dim_7</th>\n",
       "      <th>...</th>\n",
       "      <th>dim_291</th>\n",
       "      <th>dim_292</th>\n",
       "      <th>dim_293</th>\n",
       "      <th>dim_294</th>\n",
       "      <th>dim_295</th>\n",
       "      <th>dim_296</th>\n",
       "      <th>dim_297</th>\n",
       "      <th>dim_298</th>\n",
       "      <th>dim_299</th>\n",
       "      <th>dim_300</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aardvark</th>\n",
       "      <td>0.427</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.437</td>\n",
       "      <td>-0.349260</td>\n",
       "      <td>-0.553240</td>\n",
       "      <td>-0.430850</td>\n",
       "      <td>0.510470</td>\n",
       "      <td>0.40767</td>\n",
       "      <td>0.095694</td>\n",
       "      <td>-0.17689</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.500660</td>\n",
       "      <td>-0.157680</td>\n",
       "      <td>-0.77059</td>\n",
       "      <td>0.005665</td>\n",
       "      <td>-0.321810</td>\n",
       "      <td>-0.78144</td>\n",
       "      <td>0.164200</td>\n",
       "      <td>0.624030</td>\n",
       "      <td>0.17806</td>\n",
       "      <td>-0.101510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aback</th>\n",
       "      <td>0.385</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.018572</td>\n",
       "      <td>-0.091755</td>\n",
       "      <td>0.234470</td>\n",
       "      <td>-0.398870</td>\n",
       "      <td>0.14438</td>\n",
       "      <td>0.041793</td>\n",
       "      <td>0.45685</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136600</td>\n",
       "      <td>-0.410070</td>\n",
       "      <td>0.34458</td>\n",
       "      <td>-0.069210</td>\n",
       "      <td>-0.011236</td>\n",
       "      <td>-0.28098</td>\n",
       "      <td>0.070116</td>\n",
       "      <td>0.403770</td>\n",
       "      <td>-0.14337</td>\n",
       "      <td>0.065997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abacus</th>\n",
       "      <td>0.510</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.485</td>\n",
       "      <td>-0.002865</td>\n",
       "      <td>-0.071534</td>\n",
       "      <td>-0.346530</td>\n",
       "      <td>0.275440</td>\n",
       "      <td>0.19806</td>\n",
       "      <td>-0.097807</td>\n",
       "      <td>-0.13528</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.312060</td>\n",
       "      <td>-0.161740</td>\n",
       "      <td>-0.54930</td>\n",
       "      <td>0.276720</td>\n",
       "      <td>0.714070</td>\n",
       "      <td>-0.35514</td>\n",
       "      <td>-0.180200</td>\n",
       "      <td>0.405210</td>\n",
       "      <td>-0.24642</td>\n",
       "      <td>0.005458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abalone</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.709240</td>\n",
       "      <td>0.460650</td>\n",
       "      <td>-0.038441</td>\n",
       "      <td>0.039853</td>\n",
       "      <td>-0.00113</td>\n",
       "      <td>0.030408</td>\n",
       "      <td>-0.44903</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057243</td>\n",
       "      <td>0.016303</td>\n",
       "      <td>0.74038</td>\n",
       "      <td>0.018888</td>\n",
       "      <td>-0.468430</td>\n",
       "      <td>-0.53066</td>\n",
       "      <td>0.449360</td>\n",
       "      <td>0.037575</td>\n",
       "      <td>0.95823</td>\n",
       "      <td>-0.346630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandon</th>\n",
       "      <td>0.052</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.255620</td>\n",
       "      <td>-0.166040</td>\n",
       "      <td>-0.120690</td>\n",
       "      <td>-0.432870</td>\n",
       "      <td>0.10721</td>\n",
       "      <td>-0.493020</td>\n",
       "      <td>0.36993</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.588510</td>\n",
       "      <td>-0.490100</td>\n",
       "      <td>0.48357</td>\n",
       "      <td>-0.027909</td>\n",
       "      <td>-0.023546</td>\n",
       "      <td>0.18434</td>\n",
       "      <td>0.061770</td>\n",
       "      <td>-0.258670</td>\n",
       "      <td>0.14337</td>\n",
       "      <td>0.014162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          valence  arousal  dominance     dim_1     dim_2     dim_3     dim_4  \\\n",
       "word                                                                            \n",
       "aardvark    0.427    0.490      0.437 -0.349260 -0.553240 -0.430850  0.510470   \n",
       "aback       0.385    0.407      0.288  0.018572 -0.091755  0.234470 -0.398870   \n",
       "abacus      0.510    0.276      0.485 -0.002865 -0.071534 -0.346530  0.275440   \n",
       "abalone     0.500    0.480      0.412  0.709240  0.460650 -0.038441  0.039853   \n",
       "abandon     0.052    0.519      0.245  0.255620 -0.166040 -0.120690 -0.432870   \n",
       "\n",
       "            dim_5     dim_6    dim_7  ...   dim_291   dim_292  dim_293  \\\n",
       "word                                  ...                                \n",
       "aardvark  0.40767  0.095694 -0.17689  ... -0.500660 -0.157680 -0.77059   \n",
       "aback     0.14438  0.041793  0.45685  ...  0.136600 -0.410070  0.34458   \n",
       "abacus    0.19806 -0.097807 -0.13528  ... -0.312060 -0.161740 -0.54930   \n",
       "abalone  -0.00113  0.030408 -0.44903  ... -0.057243  0.016303  0.74038   \n",
       "abandon   0.10721 -0.493020  0.36993  ... -0.588510 -0.490100  0.48357   \n",
       "\n",
       "           dim_294   dim_295  dim_296   dim_297   dim_298  dim_299   dim_300  \n",
       "word                                                                          \n",
       "aardvark  0.005665 -0.321810 -0.78144  0.164200  0.624030  0.17806 -0.101510  \n",
       "aback    -0.069210 -0.011236 -0.28098  0.070116  0.403770 -0.14337  0.065997  \n",
       "abacus    0.276720  0.714070 -0.35514 -0.180200  0.405210 -0.24642  0.005458  \n",
       "abalone   0.018888 -0.468430 -0.53066  0.449360  0.037575  0.95823 -0.346630  \n",
       "abandon  -0.027909 -0.023546  0.18434  0.061770 -0.258670  0.14337  0.014162  \n",
       "\n",
       "[5 rows x 303 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VAD_words = pd.read_csv(\"NRC-VAD_glove-wiki-gigaword-300.csv\", index_col=0)\n",
    "VAD_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histograms of Valence, Arousal and Dominance respectively, word level\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x216 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Histograms of Valence, Arousal and Dominance respectively, word level')\n",
    "VAR_w = [VAD_words['valence'], VAD_words['arousal'], VAD_words['dominance']]\n",
    "fig, axes = plt.subplots(1,3,figsize=(16,3))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.hist(VAR_w[i], bins=50) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try different approaches!\n",
    "Goal is to predict the VAD values of a sentence from its input. Then it would also be great to acquire some model understanding on the way!\n",
    "### Approach 1 : average of word's VAD value\n",
    "An intuitive way of facing this problem could be to just take the mean of the VAD values for each word in the sentence. That way, if we had more negative words (valence) the sentence would naturally be more negative. The parameters to learn in this case would be those of the simple linear relation:\n",
    "$$VADsentence(x_1, x_2, \\dots x_n) = a*(VADword(x_1)+VADword(x_2)+ \\dots +VADword(x_n))/n+b$$\n",
    "Notice that they are all 3 component vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_coef(x, y): \n",
    "    # number of observations/points \n",
    "    n = np.size(x)\n",
    "  \n",
    "    # mean of x and y vector \n",
    "    m_x, m_y = np.mean(x), np.mean(y) \n",
    "  \n",
    "    # calculating cross-deviation and deviation about x \n",
    "    SS_xy = np.sum(y*x) - n*m_y*m_x \n",
    "    SS_xx = np.sum(x*x) - n*m_x*m_x \n",
    "  \n",
    "    # calculating regression coefficients \n",
    "    a = SS_xy / SS_xx \n",
    "    b = m_y - a*m_x \n",
    "  \n",
    "    return(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def normalizeString(s):\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vec(word):\n",
    "    #returns vad+300 glove vector\n",
    "    return VAD_words.loc[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "valence      0.635000\n",
       "arousal      0.279000\n",
       "dominance    0.342000\n",
       "dim_1       -0.362010\n",
       "dim_2       -0.429600\n",
       "               ...   \n",
       "dim_296      0.068602\n",
       "dim_297      0.623580\n",
       "dim_298     -0.595160\n",
       "dim_299     -0.433940\n",
       "dim_300     -0.431170\n",
       "Name: letter, Length: 303, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_vec('letter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_VAD_mean(sentence):\n",
    "    #takes a string (sentence) and returns the average VAD vector\n",
    "    sentence = sentence.lower()\n",
    "    sentence = normalizeString(sentence)\n",
    "    words = sentence.split()\n",
    "    vectors = []\n",
    "    for word in words:\n",
    "        try:\n",
    "            vec = [i for i in VAD_words.loc[word][:3]]\n",
    "            vectors.append(vec)\n",
    "        except:\n",
    "            #if word not in the lexicon then it must be neutral\n",
    "            vectors.append([.5, .5, .5])\n",
    "    valence = np.mean([vector[0] for vector in vectors])\n",
    "    arrousal = np.mean([vector[1] for vector in vectors])\n",
    "    dominance = np.mean([vector[2] for vector in vectors])\n",
    "    return valence, arrousal, dominance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.5, 0.5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_VAD_mean('..\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add columns to keep the VAD average values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb[\"V_words\"] = \"\"\n",
    "eb[\"A_words\"] = \"\"\n",
    "eb[\"D_words\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(eb)):\n",
    "    eb['V_words'][i], eb['A_words'][i], eb['D_words'][i] = compute_VAD_mean(eb['text'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>V</th>\n",
       "      <th>A</th>\n",
       "      <th>D</th>\n",
       "      <th>text</th>\n",
       "      <th>V_words</th>\n",
       "      <th>A_words</th>\n",
       "      <th>D_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.20</td>\n",
       "      <td>Remember what she said in my last letter? \"</td>\n",
       "      <td>0.545667</td>\n",
       "      <td>0.466778</td>\n",
       "      <td>0.477333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.80</td>\n",
       "      <td>If I wasn't working here.</td>\n",
       "      <td>0.534286</td>\n",
       "      <td>0.512143</td>\n",
       "      <td>0.510857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>..\"</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.22</td>\n",
       "      <td>Goodwill helps people get off of public assistance.</td>\n",
       "      <td>0.614444</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.570111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>3.55</td>\n",
       "      <td>3.27</td>\n",
       "      <td>3.46</td>\n",
       "      <td>Sherry learned through our Future Works class that she could rise out of the mire of the welfare system and support ...</td>\n",
       "      <td>0.596875</td>\n",
       "      <td>0.474125</td>\n",
       "      <td>0.549542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   split     V     A     D  \\\n",
       "0  train  3.00  3.00  3.20   \n",
       "1   test  2.80  3.10  2.80   \n",
       "2  train  3.00  3.00  3.00   \n",
       "3  train  3.44  3.00  3.22   \n",
       "4  train  3.55  3.27  3.46   \n",
       "\n",
       "                                                                                                                      text  \\\n",
       "0                                                                              Remember what she said in my last letter? \"   \n",
       "1                                                                                                If I wasn't working here.   \n",
       "2                                                                                                                      ..\"   \n",
       "3                                                                      Goodwill helps people get off of public assistance.   \n",
       "4  Sherry learned through our Future Works class that she could rise out of the mire of the welfare system and support ...   \n",
       "\n",
       "    V_words   A_words   D_words  \n",
       "0  0.545667  0.466778  0.477333  \n",
       "1  0.534286  0.512143  0.510857  \n",
       "2       0.5       0.5       0.5  \n",
       "3  0.614444  0.483333  0.570111  \n",
       "4  0.596875  0.474125  0.549542  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we only consider the training sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1 = eb[eb.split=='train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating coefficients for valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients for Valence: a = 2.839421168278393, b = 1.454510105282507\n"
     ]
    }
   ],
   "source": [
    "a_val, b_val = estimate_coef(train_1['V_words'], train_1['V'])\n",
    "print('Coefficients for Valence: a = '+str(a_val)+', b = '+str(b_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the approach\n",
    "We will now consider the test set, we'll predict the valence of the text and we'll compare it with the actual value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1 = eb[eb.split=='test']\n",
    "prediction_1_val = []\n",
    "for i in test_1['V_words']:\n",
    "    prediction_1_val.append(a_val*i + b_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error of approach 1 for valence = 0.099985207718358\n"
     ]
    }
   ],
   "source": [
    "MSE_Val = ((prediction_1_val - test_1['V'].values)**2).mean()\n",
    "print('Mean squared error of approach 1 for valence = '+str(MSE_Val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at a couple of examples to see if it isn't a generalisation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------\n",
      "When my father died, a year after my mother, my sisters and I cleaned out their apartment.\n",
      "Valence = 2.0, predicted valence = 2.9570371401631563\n",
      "--------------------------------------------------------------------------------------\n",
      "Outdated baby food found on shelves\n",
      "Valence = 1.89, predicted valence = 3.217317413922009\n",
      "--------------------------------------------------------------------------------------\n",
      "So empty it hurt.\n",
      "Valence = 2.0, predicted valence = 2.4483075141799446\n",
      "--------------------------------------------------------------------------------------\n",
      "\"This is a criminal act and it certainly puts things in a different league,\"\n",
      "Valence = 2.0, predicted valence = 2.852316583266413\n"
     ]
    }
   ],
   "source": [
    "for i in [7518, 4949, 7066, 2947]:\n",
    "    print('--------------------------------------------------------------------------------------')\n",
    "    val_word = test_1['V_words'][i]\n",
    "    val, pred = test_1['V'][i], val_word*a_val + b_val\n",
    "    print(test_1['text'][i])\n",
    "    print('Valence = {}, predicted valence = {}'.format(val,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------\n",
      "And the last lesson -- have fun .\n",
      "Valence = 4.0, predicted valence = 3.2307708618383764\n",
      "--------------------------------------------------------------------------------------\n",
      "Canadian breakthrough offers hope on autism\n",
      "Valence = 3.88, predicted valence = 3.036067696013572\n",
      "--------------------------------------------------------------------------------------\n",
      "We slammed against the doorway and I was laughing too, the pulse close enough to shake the doorframe and set up vibrations in my chest, Rachel in my arms because she’d used me to soften her landing.\n",
      "Valence = 4.1, predicted valence = 2.8976641154777454\n",
      "--------------------------------------------------------------------------------------\n",
      "The proverbial hospitality and warm welcome are still here.\n",
      "Valence = 3.75, predicted valence = 3.188260670633294\n"
     ]
    }
   ],
   "source": [
    "for i in [4455, 4618, 3871, 2613]:\n",
    "    print('--------------------------------------------------------------------------------------')\n",
    "    val_word = test_1['V_words'][i]\n",
    "    val, pred = test_1['V'][i], val_word*a_val + b_val\n",
    "    print(test_1['text'][i])\n",
    "    print('Valence = {}, predicted valence = {}'.format(val,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, for arrousal and dominance we have the following errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error of approach 1 for valence = 0.05831941043231876\n",
      "Mean squared error of approach 1 for valence = 0.0436326241882095\n"
     ]
    }
   ],
   "source": [
    "a_arr, b_arr = estimate_coef(train_1['A_words'], train_1['A'])\n",
    "a_dom, b_dom = estimate_coef(train_1['D_words'], train_1['D'])\n",
    "prediction_1_arr, prediction_1_dom = [], []\n",
    "for i in test_1['A_words']:\n",
    "    prediction_1_arr.append(a_arr*i + b_arr)\n",
    "for i in test_1['D_words']:\n",
    "    prediction_1_dom.append(a_dom*i + b_dom)\n",
    "MSE_Arr = ((prediction_1_arr - test_1['A'].values)**2).mean()\n",
    "print('Mean squared error of approach 1 for valence = '+str(MSE_Arr))\n",
    "MSE_Dom = ((prediction_1_dom - test_1['D'].values)**2).mean()\n",
    "print('Mean squared error of approach 1 for valence = '+str(MSE_Dom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (ST7)",
   "language": "python",
   "name": "st7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
